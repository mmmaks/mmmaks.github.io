---
layout: post
title: Activation functions
---

Activation function is used to determine the output of neural network like yes or no. It maps the
resulting values in between 0 to 1 or -1 to 1 etc. (depending upon the function).

### Sigmoid or Logistic Activation Function

Sigmoid function is used when we need to predict the probability as an output.

![_config.yml]({{ site.baseurl }}/images/sigmoid.png)

### Tanh Activation Function

This is like sigmoid but values ranges from -1 to 1.

![_config.yml]({{ site.baseurl }}/images/sigmoid.png)

The easiest way to make your first post is to edit this one. Go into /_posts/ and update the Hello World markdown file. For more instructions head over to the [Jekyll Now repository](https://github.com/barryclark/jekyll-now) on GitHub.